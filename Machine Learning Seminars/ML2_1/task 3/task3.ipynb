{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import requests\n",
    "import dvc.api\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем датасет твиттера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWITTER = './twitter.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(TWITTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>is so sad for my APL friend.............</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>I missed the New Moon trailer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I've been at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>i think mi bf is cheating on me!!!       T_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578609</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Zzzzzz.... Finally! Night tweeters!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578610</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Zzzzzzz, sleep well people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578611</th>\n",
       "      <td>0.0</td>\n",
       "      <td>ZzzZzZzzzZ... wait no I have homework.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578612</th>\n",
       "      <td>0.0</td>\n",
       "      <td>ZzZzzzZZZZzzz meh, what am I doing up again?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578613</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Zzzzzzzzzzzzzzzzzzz, I wish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1578614 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tag                                            message\n",
       "0        0.0           is so sad for my APL friend.............\n",
       "1        0.0                   I missed the New Moon trailer...\n",
       "2        1.0                            omg its already 7:30 :O\n",
       "3        0.0  .. Omgaga. Im sooo  im gunna CRy. I've been at...\n",
       "4        0.0       i think mi bf is cheating on me!!!       T_T\n",
       "...      ...                                                ...\n",
       "1578609  1.0                Zzzzzz.... Finally! Night tweeters!\n",
       "1578610  1.0                         Zzzzzzz, sleep well people\n",
       "1578611  0.0             ZzzZzZzzzZ... wait no I have homework.\n",
       "1578612  0.0       ZzZzzzZZZZzzz meh, what am I doing up again?\n",
       "1578613  0.0                        Zzzzzzzzzzzzzzzzzzz, I wish\n",
       "\n",
       "[1578614 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве токенизатора предложений используем готовый из LaBSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/LaBSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is so sad for my APL friend.............'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"message\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для словаря создадим отдельный класс, который загружает данный из наборов предложений, также он позволяет менять количество слов в словаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "class WordsVocabulary:\n",
    "    def __init__(self, freq_threshold):\n",
    "        self.idx2word = {0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[UNK]'}\n",
    "        self.word2idx = {'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[UNK]': 3}\n",
    "        self.freq_threshold = freq_threshold\n",
    "        self.frequencies = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx2word)\n",
    "\n",
    "    def build_vocabulary(self, sents, tokenizer, voc_size = None):\n",
    "        idx = len(self.word2idx)\n",
    "        for sent in tqdm.tqdm(sents):\n",
    "            if(type(sent) == str):\n",
    "                sent = tokenizer.tokenize(sent)\n",
    "                for word in sent:\n",
    "                    if word not in self.frequencies:\n",
    "                        self.frequencies[word] = 1\n",
    "                    else:\n",
    "                        self.frequencies[word] += 1\n",
    "        \n",
    "        \n",
    "        if voc_size == None:\n",
    "            for word in self.frequencies.keys():\n",
    "                if self.frequencies[word] >= self.freq_threshold:\n",
    "                    self.word2idx[word] = idx\n",
    "                    self.idx2word[idx] = word\n",
    "                    idx += 1\n",
    "        else:\n",
    "            words_sorted_by_frequencies = heapq.nlargest(voc_size - len(self.idx2word), self.frequencies, key=self.frequencies.get)\n",
    "            for word in words_sorted_by_frequencies:\n",
    "                self.word2idx[word] = idx\n",
    "                self.idx2word[idx] = word\n",
    "                idx += 1\n",
    "    def rebuild_vocabulary(self, voc_size):\n",
    "        self.idx2word = {0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[UNK]'}\n",
    "        self.word2idx = {'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[UNK]': 3}\n",
    "        idx = len(self.word2idx)\n",
    "        words_sorted_by_frequencies = heapq.nlargest(voc_size - len(self.idx2word), self.frequencies, key=self.frequencies.get)\n",
    "        for word in words_sorted_by_frequencies:\n",
    "            self.word2idx[word] = idx\n",
    "            self.idx2word[idx] = word\n",
    "            idx += 1\n",
    "    def numericalize(self, tokens):\n",
    "        return [self.word2idx[token] if token in self.word2idx else self.word2idx['[UNK]']\n",
    "                for token in tokens]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1578614/1578614 [01:12<00:00, 21890.29it/s]\n"
     ]
    }
   ],
   "source": [
    "wordvoc = WordsVocabulary(1)\n",
    "wordvoc.build_vocabulary(data[\"message\"], tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wordvoc.pickle', 'wb') as f:\n",
    "    pickle.dump(wordvoc, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно загрузить словарь, предварительно создав класс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wordvoc.pickle', 'rb') as f:\n",
    "    wordvoc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88154"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordvoc.word2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомогательные функции для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(dataset, word2idx, tokenizer, batch_size=64, shuffle=True):\n",
    "    X, Y = dataset, dataset\n",
    "    PAD = word2idx['[PAD]']\n",
    "    n_samples = len(X)\n",
    "\n",
    "# генерим список индексов\n",
    "    list_of_indexes = np.linspace(\n",
    "        0, n_samples - 1, n_samples, dtype=np.int64)\n",
    "    List_X = []\n",
    "    List_Y = []\n",
    "    \n",
    "# если нужно перемешать, то перемешиваем\n",
    "    if shuffle:\n",
    "        np.random.shuffle(list_of_indexes)\n",
    "        \n",
    "\n",
    "# сгенерируем список индексов, по этим индексам,\n",
    "# сделаем новый перемешаный спиисок токенов и тэгов\n",
    "    for indx in list_of_indexes:\n",
    "        if(type(X[indx]) == str) and (type(X[indx]) == str):\n",
    "            List_X.append(tokenizer.tokenize(X[indx]))\n",
    "            List_Y.append(tokenizer.tokenize(Y[indx]))\n",
    "    n_samples = len(List_X)\n",
    "    n_batches = n_samples//batch_size\n",
    "    if n_samples%batch_size != 0:\n",
    "        n_batches+=1\n",
    "        \n",
    "    # For each k yield pair x and y\n",
    "    for k in range(n_batches):\n",
    "# указываем текущии размер батча\n",
    "        this_batch_size = batch_size\n",
    "    \n",
    "# если мы выдаем последний батч, то его нужно обрезать\n",
    "        if k == n_batches - 1:\n",
    "            if n_samples%batch_size > 0:\n",
    "                this_batch_size = n_samples%batch_size\n",
    "                \n",
    "        This_X = List_X[k*batch_size:k*batch_size + this_batch_size]\n",
    "        This_Y = List_Y[k*batch_size:k*batch_size + this_batch_size]\n",
    "        \n",
    "        This_X_line = [\n",
    "                       [word2idx.get(char, 0) for char in sent]\\\n",
    "                       for sent in This_X]\n",
    "        This_Y_line = [\n",
    "                       [word2idx.get('[CLS]', 0)]\\\n",
    "                       + [word2idx.get(char, 0) for char in sent]\\\n",
    "                       + [word2idx.get('[SEP]', 0)]\\\n",
    "                       for sent in This_Y]\n",
    "        List_of_length_x = [len(sent) for sent in This_X_line]\n",
    "        length_of_sentence_x = max(List_of_length_x)\n",
    "        List_of_length_y = [len(sent) for sent in This_Y_line]\n",
    "        length_of_sentence_y = max(List_of_length_y)\n",
    "\n",
    "        x_arr = np.ones(shape=[this_batch_size, length_of_sentence_x])*PAD\n",
    "        y_arr = np.ones(shape=[this_batch_size, length_of_sentence_y])*PAD\n",
    "\n",
    "        for i in range(this_batch_size):\n",
    "            x_arr[i, :len(This_X_line[i])] = This_X_line[i]\n",
    "            y_arr[i, :len(This_Y_line[i])] = This_Y_line[i]\n",
    "\n",
    "        x = torch.LongTensor(x_arr)\n",
    "        y = torch.LongTensor(y_arr)\n",
    "        lengths = torch.LongTensor(List_of_length_x)\n",
    "\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP = 1\n",
    "def train_on_batch(model, batch_of_x, batch_of_y, optimizer, loss_function):\n",
    "    encoder, decoder = model\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    encoder.zero_grad()\n",
    "    decoder.zero_grad()\n",
    "    def closure():\n",
    "        d, h, c = encoder(batch_of_x.to(encoder.device))\n",
    "        output = decoder(\n",
    "            batch_of_y.to(decoder.device), \n",
    "            h=h.to(decoder.device)[:, -decoder.num_layers:, :], \n",
    "            c=c.to(decoder.device)[:, -decoder.num_layers:, :])\n",
    "\n",
    "        loss = loss_function(output[:, :-1, :].transpose(1, 2), batch_of_y.to(decoder.device)[:, 1:])\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    \n",
    "    torch.nn.utils.clip_grad_norm_(model[0].parameters(), CLIP) # Клипуем градиент на случай его взрыва\n",
    "    torch.nn.utils.clip_grad_norm_(model[1].parameters(), CLIP)\n",
    "    optimizer.step(closure)\n",
    "    \n",
    "    return closure().cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_epoch(train_generator, model, loss_function, optimizer, callback = None):\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    for it, (batch_of_x, batch_of_y) in enumerate(train_generator):\n",
    "        local_loss = train_on_batch(\n",
    "            model, batch_of_x, batch_of_y, optimizer, loss_function)\n",
    "        if callback is not None:\n",
    "            with torch.no_grad():\n",
    "                callback(model, local_loss)\n",
    "        train_generator.set_postfix({'train batch loss': local_loss})\n",
    "\n",
    "        epoch_loss += local_loss*len(batch_of_x)\n",
    "        total += len(batch_of_x)\n",
    "    \n",
    "    return epoch_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def trainer(count_of_epoch, \n",
    "            batch_size,\n",
    "            model,\n",
    "            dataset,\n",
    "            word2idx,\n",
    "            loss_function,\n",
    "            optimizer,tokenizer, callback = None):\n",
    "    iterations = tqdm.notebook.tqdm(range(count_of_epoch))\n",
    "    epoch_loss = 0\n",
    "    for it in iterations:\n",
    "        optima = optimizer\n",
    "\n",
    "        number_of_batch = len(dataset)//batch_size + (len(dataset)%batch_size>0)\n",
    "        generator = tqdm.notebook.tqdm(\n",
    "            batch_generator(dataset, word2idx, tokenizer, batch_size),\n",
    "            leave=False, total=number_of_batch)\n",
    "        \n",
    "        epoch_loss = train_epoch(\n",
    "            train_generator = generator, model = model, \n",
    "            loss_function = loss_function, \n",
    "            optimizer = optima, callback=callback)\n",
    "\n",
    "        iterations.set_postfix({'train epoch loss': epoch_loss})\n",
    "    model[0].eval()\n",
    "    model[1].eval()\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Энкодер для нашего автокодировщика, основной блок это LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "        \n",
    "    def __init__(self,\n",
    "                 vocab_dim,\n",
    "                 emb_dim = 10, \n",
    "                 hidden_dim = 10,\n",
    "                 num_layers = 3,\n",
    "                 bidirectional = False, dropout = 0.5, batch_norm = False):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.num_direction = int(bidirectional + 1)\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(vocab_dim, emb_dim)\n",
    "\n",
    "        self.encoder = torch.nn.LSTM(\n",
    "            emb_dim, hidden_dim, num_layers, bidirectional = bidirectional)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        input = self.dropout(self.embedding(input))\n",
    "        input = torch.transpose(input, 0, 1)\n",
    "        d, (h, c) = self.encoder(input)\n",
    "        return d, torch.transpose(h, 0, 1) , torch.transpose(c, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Декодер для нашего автокодировщика, основной блок это LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def __init__(self,\n",
    "                 vocab_dim,\n",
    "                 output_dim, word2idx,\n",
    "                 emb_dim = 10, \n",
    "                 hidden_dim = 10,\n",
    "                 num_layers = 3,\n",
    "                 bidirectional = False, dropout = 0.5, batch_norm = False):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.num_direction = int(bidirectional + 1)\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(vocab_dim, self.emb_dim)\n",
    "\n",
    "        self.decoder = torch.nn.LSTM(\n",
    "            emb_dim, hidden_dim, num_layers, bidirectional = bidirectional)\n",
    "\n",
    "        self.linear = torch.nn.Linear(\n",
    "            self.num_direction*hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.word2idx = word2idx\n",
    "\n",
    "    def forward(self, real=None, h = None, c = None, max_len = 50):\n",
    "        batch_size = 1\n",
    "        if h is not None:\n",
    "            batch_size = h.shape[0]\n",
    "        if c is not None:\n",
    "            batch_size = c.shape[0]\n",
    "        if real is not None:\n",
    "            batch_size = real.shape[0]\n",
    "\n",
    "        #Для обучения нам нужно, чтобы модель принимала реальную строку в качестве ввода\n",
    "        if real is not None:\n",
    "            input = self.dropout(self.embedding(real))\n",
    "\n",
    "            if h is None:\n",
    "                h = torch.randn(\n",
    "                    (batch_size, self.num_layers, self.num_direction*self.hidden_dim)).to(\n",
    "                        self.device\n",
    "                    )\n",
    "            if c is None:\n",
    "                c = torch.randn(\n",
    "                    (batch_size, self.num_layers, self.num_direction*self.hidden_dim)).to(\n",
    "                        self.device\n",
    "                    )\n",
    "\n",
    "            input = torch.transpose(input, 0, 1)\n",
    "            h = torch.transpose(h, 0, 1)\n",
    "            c = torch.transpose(c, 0, 1)\n",
    "            d, _ = self.decoder(input, (h, c))\n",
    "            answers = self.linear(d)\n",
    "        #Для инференса нам нужно, чтобы модель автоматически подставаля в качесте первого элемента входа символ начала строки\n",
    "        else:\n",
    "            input = self.embedding(\n",
    "                torch.tensor(\n",
    "                    [[self.word2idx['[CLS]']] for _ in range(\n",
    "                        batch_size)]).long().to(\n",
    "                        self.device\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            if h is None:\n",
    "                h = torch.randn(\n",
    "                    (batch_size, self.num_layers, self.num_direction*self.hidden_dim)).to(\n",
    "                        self.device\n",
    "                    )\n",
    "            if c is None:\n",
    "                c = torch.randn(\n",
    "                    (batch_size, self.num_layers, self.num_direction*self.hidden_dim)).to(\n",
    "                        self.device\n",
    "                    )\n",
    "\n",
    "            input = torch.transpose(input, 0, 1)\n",
    "            h = torch.transpose(h, 0, 1)\n",
    "            c = torch.transpose(c, 0, 1)\n",
    "\n",
    "            answers = torch.zeros(\n",
    "                (max_len, input.shape[1], self.output_dim)).to(\n",
    "                    self.device)\n",
    "                \n",
    "            for i in range(max_len):\n",
    "                d, (h, c) = self.decoder(input, (h, c))\n",
    "                answers[i, :, :] = self.linear(d)[0]\n",
    "                input = self.embedding(\n",
    "                    torch.argmax(answers[i:i+1, :, :], dim=-1))\n",
    "\n",
    "        return torch.transpose(answers, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_dim=len(wordvoc.word2idx), \n",
    "                  num_layers=2, emb_dim=100, hidden_dim=100, dropout= 0.5)\n",
    "encoder.to(device)\n",
    "decoder = Decoder(vocab_dim=len(wordvoc.word2idx), \n",
    "                  output_dim=len(wordvoc.word2idx), word2idx=wordvoc.word2idx, num_layers=2, emb_dim=100, hidden_dim=100, dropout= 0.5)\n",
    "decoder.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(encoder.parameters()) + list(decoder.parameters()), lr=1e-3)\n",
    "loss_function = torch.nn.CrossEntropyLoss(ignore_index=wordvoc.word2idx['[PAD]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = torch.tensor([[wordvoc.word2idx.get(char, 0) for char in tokenizer.tokenize(data[\"message\"][0])]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, h, c = encoder(sent.to(encoder.device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Восстановление строки из датасета с помощью модели до обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##sonmathsrifdeledele##chargergheTOFmankmankTOFmank##chdHawaiTOF##chd##chdrssmankshaftvlagevlagetratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamiento\n"
     ]
    }
   ],
   "source": [
    "sent = torch.tensor([[wordvoc.word2idx.get(char, 0) for char in tokenizer.tokenize(data[\"message\"][0])]])\n",
    "d, h, c = encoder(sent.to(encoder.device))\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "indexes = torch.argmax(\n",
    "    decoder(max_len=100,\n",
    "            h=h, \n",
    "            c=c), dim=-1).detach().cpu().numpy()[0]\n",
    "list_of_char = []\n",
    "for idx in indexes:\n",
    "    if idx == wordvoc.word2idx['[SEP]']:\n",
    "        break\n",
    "    list_of_char.append(wordvoc.idx2word[idx])\n",
    "print(''.join(list_of_char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строка, которую дает энкодер на случайном векторе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##endoCambridgeCambridgeMinMinMinMinAsiavlageBergmantailoredtodos##ilotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamiento\n",
      "joiningGrossGross##elemTOFtratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamiento\n",
      "##dym##nnya##nnyaRegistrarYungYungYungYunginstallationsmesma##hishrssmesmaComu1600deledeleTOFtratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamiento\n",
      "##tzungcartonsPresentmuseetmuseet##uwiByrdMortmasalamankmankseesesimultaneouslysimultaneouslyghewinningwinningwinningTOFTOF##chd##chd##ectmathsrssmasalamankmasalamankmankwathiwathimasalamasalamank##ggymankwathimasalamank##ggymankwathimasalamankmankwathi##ggymasalamankmankwathi##ggymasalamankmankwathi##ggymasalamankmankwathi##ggymasalamankmankwathi##ggymasalamankmankwathi##ggymasalamankmankwathi##ggymasalamankmankwathi##ggymasalamankmankwathi##ggymasalamankmankwathi##ggymasalamankmankwathi##ggymasalamank\n",
      "tals817kole##onale##onale##liman##limanrssSinoSinodesentripletripletripleHarcourtbsbsBTSMerkel##gati##gati##gaticonfirmed##ptosconfirmedsimultaneouslysimultaneouslyconfirmedsimultaneously1600simultaneouslywinningwinningwinningTOF##chd##ectsimultaneouslylec##chd##chd##chd##chdrssvlageshaftvlagetratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamiento\n",
      "##tars##tarsTsunamiTsunamishortstraditionallysimultaneouslyNOVIconfirmedsimultaneouslysimultaneouslyghewinningwinning##chdTOF##chd##chdHawaitratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamiento\n",
      "SKUSKU##jniadvocacy##erumtratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamiento\n",
      "creekkuroskurosmesmamesmakurosmasalamasalamasalamank##àdumatingsimultaneouslyPattyPattyclasse##ratanNeedleGardinermankaimer##olasInternakaterekatereadvocacymasalamasalamankmankwathi##ggymasalamankmankwathi##ggymasalamankmankwathi##ggymasalamankmankwathi##ggymasalamankmankwathi##ggymasalamankmankwathi##ggymasalamankmankwathi##ggymasalamankmankwathi##ggymasalamankmankwathi##ggymasalamankmankwathi##ggymasalamankmankwathi##ggymasalamankmankwathi##ggymasalamankmankwathi##ggymasalamankmankwathi##ggymasalamankmank\n",
      "bentaLaylavarnaclasseadvocacy##jenteLofotentratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamiento\n",
      "NCCGayeGayeGaye##ococcusAusten##ococcuscorrecta##olasmankmank##chd##chd##chdHawai##chd##chd##chdshafttratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamientotratamiento\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    indexes = torch.argmax(\n",
    "        decoder(max_len=100,\n",
    "                h=0.1*torch.randn(\n",
    "                    (1, decoder.num_layers, decoder.num_direction*decoder.hidden_dim)).to(\n",
    "                        decoder.device\n",
    "                ), \n",
    "                c=torch.randn(\n",
    "                    (1, decoder.num_layers, decoder.num_direction*decoder.hidden_dim)).to(\n",
    "                    decoder.device\n",
    "                )), dim=-1).detach().cpu().numpy()[0]\n",
    "    list_of_char = []\n",
    "    for idx in indexes:\n",
    "        if idx == wordvoc.word2idx['[SEP]']:\n",
    "            break\n",
    "        list_of_char.append(wordvoc.idx2word[idx])\n",
    "    print(''.join(list_of_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1578614"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем сеть на небольших значениях гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer(count_of_epoch = 100,\n",
    "        batch_size = 16,\n",
    "        model = (encoder, decoder),\n",
    "        dataset = data.head(n=10*64 + 10)[\"message\"], \n",
    "        tokenizer=tokenizer,\n",
    "        word2idx = wordvoc.word2idx,\n",
    "        loss_function = loss_function,\n",
    "        optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), 'encoder_0.pt')\n",
    "torch.save(decoder.state_dict(), 'decoder_0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.load_state_dict(torch.load('encoder_0.pt'))\n",
    "decoder.load_state_dict(torch.load('decoder_0.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, h, c = encoder(sent.to(encoder.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 100])\n"
     ]
    }
   ],
   "source": [
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no pavel tonight &lt;Tigersfan &gt;'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"message\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = torch.tensor([[wordvoc.word2idx.get(char, 0) for char in tokenizer.tokenize(data[\"message\"][100])]])\n",
    "y = torch.tensor([[wordvoc.word2idx.get('[CLS]', 0)]\\\n",
    "                       + [wordvoc.word2idx.get(char, 0) for char in tokenizer.tokenize(data[\"message\"][100])]\\\n",
    "                       + [wordvoc.word2idx.get('[SEP]', 0)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@dan##rega##n@lini##nini##S##S##S--\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "d, h, c = encoder(sent.to(encoder.device))\n",
    "indexes = torch.argmax(\n",
    "    decoder(\n",
    "        max_len=100,\n",
    "        h=h.to(decoder.device)[:, -decoder.num_layers:, :], \n",
    "        c=c.to(decoder.device)[:, -decoder.num_layers:, :]), dim=-1).detach().cpu().numpy()[0]\n",
    "list_of_char = []\n",
    "for idx in indexes:\n",
    "    if idx == wordvoc.word2idx['[SEP]']:\n",
    "        break\n",
    "    list_of_char.append(wordvoc.idx2word[idx])\n",
    "print(''.join(list_of_char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Маленькая сеть не позволяет получить что-то вразумительное, в основном либо этой самый популярный в датасете символ точки, либо какая-то бессмыслица. Единственное преимущество такой сети, что она учится быстро"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  96, 1409, 1417,   75,   96, 1546, 1547, 1480, 1480, 1480,   80,\n",
       "         80,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "          2])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##uu##uu##uu\n",
      "##ay\n",
      "...\n",
      "if..\n",
      "##on\n",
      "...\n",
      "www\n",
      ";.\n",
      "just\n",
      "aunt...\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    indexes = torch.argmax(\n",
    "        decoder(max_len=100,\n",
    "                h=0.1*torch.randn(\n",
    "                    (1, decoder.num_layers, decoder.num_direction*decoder.hidden_dim)).to(\n",
    "                        decoder.device\n",
    "                ), \n",
    "                c=torch.randn(\n",
    "                    (1, decoder.num_layers, decoder.num_direction*decoder.hidden_dim)).to(\n",
    "                    decoder.device\n",
    "                )), dim=-1).detach().cpu().numpy()[0]\n",
    "    list_of_char = []\n",
    "    for idx in indexes:\n",
    "        if idx == wordvoc.word2idx['[SEP]']:\n",
    "            break\n",
    "        list_of_char.append(wordvoc.idx2word[idx])\n",
    "    print(''.join(list_of_char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тоже самое получается для случайных векторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удобство дальнейшего поиска по сетке представим параметры сети в виде словаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_encoder = dict()\n",
    "config_encoder['vocab_dim'] = len(wordvoc.word2idx)\n",
    "config_encoder['emb_dim'] = 100\n",
    "config_encoder['hidden_dim'] = 30\n",
    "config_encoder['num_layers'] = 4\n",
    "config_encoder['bidirectional'] = False\n",
    "config_encoder['dropout'] = 0.7\n",
    "config_encoder['batch_norm'] = False\n",
    "\n",
    "config_decoder= dict()\n",
    "config_decoder['vocab_dim'] = len(wordvoc.word2idx)\n",
    "config_decoder['output_dim'] = len(wordvoc.word2idx)\n",
    "config_decoder['emb_dim'] = 100\n",
    "config_decoder['hidden_dim'] = 30\n",
    "config_decoder['num_layers'] = 4\n",
    "config_decoder['bidirectional'] = False\n",
    "config_decoder['dropout'] = 0.7\n",
    "config_decoder['batch_norm'] = False\n",
    "config_decoder['word2idx'] = wordvoc.word2idx\n",
    "\n",
    "encoder, decoder = Encoder(**config_encoder), Decoder(**config_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 23:49:19.688774: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-07 23:49:20.552254: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В основном callback нам нужен для удобной записи в tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class callback():\n",
    "    def __init__(self, writer, batch_generator, loss_function, metrics, hparams,  delimeter = 100, batch_size=64):\n",
    "        self.step = 0\n",
    "        self.writer = writer\n",
    "        self.delimeter = delimeter\n",
    "        self.loss_function = loss_function\n",
    "        self.batch_size = batch_size\n",
    "        self.hparams = hparams\n",
    "        self.batch_generator = batch_generator\n",
    "        self.metrics = metrics\n",
    "\n",
    "    def forward(self, model, loss):\n",
    "        self.step += 1\n",
    "        with self.writer.as_default():\n",
    "            hp.hparams(self.hparams)\n",
    "            tf.summary.scalar('Loss', loss, self.step)\n",
    "        \n",
    "        if self.step % self.delimeter == 0:\n",
    "            encoder, decoder = model\n",
    "            pred = []\n",
    "            real = []\n",
    "            test_loss = 0\n",
    "            encoder.eval()\n",
    "            decoder.eval()\n",
    "            total = 0\n",
    "            for its, (x_batch, y_batch) in enumerate(self.batch_generator):\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                with torch.no_grad():\n",
    "                    d, h, c = encoder(x_batch.to(encoder.device))\n",
    "                    output = decoder(\n",
    "                        y_batch.to(decoder.device), \n",
    "                        h=h.to(decoder.device)[:, -decoder.num_layers:, :], \n",
    "                        c=c.to(decoder.device)[:, -decoder.num_layers:, :])\n",
    "\n",
    "                local_loss = loss_function(output[:, :-1, :].transpose(1, 2), y_batch.to(decoder.device)[:, 1:]).cpu().item()\n",
    "                test_loss += local_loss*len(x_batch)\n",
    "                total += len(x_batch)\n",
    "            if(total > 0):\n",
    "                test_loss /= total\n",
    "            with self.writer.as_default():\n",
    "                tf.summary.scalar(self.metrics, test_loss, self.step)\n",
    "          \n",
    "    def __call__(self, model, loss):\n",
    "        return self.forward(model, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna дает удобный интерфейс для оптимизации по гиперпараметрам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import optuna_dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    list(encoder.parameters()) + list(decoder.parameters()), lr=1e-3)\n",
    "loss_function = torch.nn.CrossEntropyLoss(ignore_index=wordvoc.word2idx['[PAD]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hp нужен для записи значений гиперпараметров в tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_VOCAB_DIM = hp.HParam('vocab_dim', hp.IntInterval(1* 1000, 10* 1000))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.5, 0.8))\n",
    "HP_BATCH_NORM = hp.HParam('batch_norm', hp.Discrete([True, False]))\n",
    "HP_HIDDEN_DIM = hp.HParam('hidden_dim', hp.IntInterval(5, 30))\n",
    "HP_EMB_DIM = hp.HParam('emb_dim', hp.IntInterval(50, 100))\n",
    "HP_NUM_LAYERS = hp.HParam('num_layers', hp.IntInterval(1, 4))\n",
    "METRICS_NAME = \"Accuracy\"\n",
    "DELIMETER = 100\n",
    "IMAGE_SIZE = 28\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE  = 16\n",
    "COLORS = 1\n",
    "MIN_CHANNELS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 23:49:30.609091: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-07 23:49:30.609490: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "logs_dir = 'logs/hparam_tuning'\n",
    "writer_hparam = tf.summary.create_file_writer('logs/hparam_tuning')\n",
    "with writer_hparam.as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_VOCAB_DIM,\n",
    "      HP_EMB_DIM,\n",
    "      HP_HIDDEN_DIM,\n",
    "      HP_NUM_LAYERS,\n",
    "      HP_BATCH_NORM,\n",
    "      HP_DROPOUT],\n",
    "    metrics=[hp.Metric(METRICS_NAME , display_name='Accuracy')],\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 342712), started 0:00:23 ago. (Use '!kill 342712' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a7b0fa57e2ad0709\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a7b0fa57e2ad0709\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/hparam_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRIALS = 10\n",
    "def objective(trial):\n",
    "    #получаем от optuna случайно полученные значения гиперпараметров\n",
    "    run_number = trial.number\n",
    "    run_name = logs_dir + f'/run-{run_number}'\n",
    "    print(\"Current run: \" + run_name)\n",
    "    vocab_dim =  trial.suggest_int('vocab_dim', 70, 88) * 1000\n",
    "    dropout = trial.suggest_float('dropout', 0.4, 0.6)\n",
    "    emb_dim = trial.suggest_int('emb_dim', 5, 15)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 5, 15)\n",
    "    batch_norm = trial.suggest_categorical('batch_norm', [True, False])\n",
    "    num_layers = trial.suggest_int('layers_count', 2, 4)\n",
    "\n",
    "    writer = tf.summary.create_file_writer(run_name)\n",
    "\n",
    "    hparams = {\n",
    "      HP_VOCAB_DIM: vocab_dim,\n",
    "      HP_EMB_DIM:  emb_dim,\n",
    "      HP_HIDDEN_DIM: hidden_dim,\n",
    "      HP_NUM_LAYERS: num_layers,\n",
    "      HP_BATCH_NORM: batch_norm,\n",
    "      HP_DROPOUT: dropout\n",
    "    }\n",
    "    wordvoc.rebuild_vocabulary(hparams[HP_VOCAB_DIM])\n",
    "    #Параметры декодера\n",
    "    config_decoder = dict()\n",
    "    config_decoder['vocab_dim'] = len(wordvoc.word2idx)\n",
    "    config_decoder['output_dim'] = len(wordvoc.word2idx)\n",
    "    config_decoder['emb_dim'] = hparams[HP_EMB_DIM]\n",
    "    config_decoder['hidden_dim'] = hparams[HP_HIDDEN_DIM]\n",
    "    config_decoder['num_layers'] = hparams[HP_NUM_LAYERS]\n",
    "    config_decoder['bidirectional'] = False\n",
    "    config_decoder['dropout'] = hparams[HP_DROPOUT]\n",
    "    config_decoder['batch_norm'] = hparams[HP_BATCH_NORM]\n",
    "    config_decoder['word2idx'] = wordvoc.word2idx\n",
    "    #Параметры энеодера\n",
    "    config_encoder = dict()\n",
    "    config_encoder['vocab_dim'] = len(wordvoc.word2idx)\n",
    "    config_encoder['emb_dim'] = hparams[HP_EMB_DIM]\n",
    "    config_encoder['hidden_dim'] = hparams[HP_HIDDEN_DIM]\n",
    "    config_encoder['num_layers'] = hparams[HP_NUM_LAYERS]\n",
    "    config_encoder['bidirectional'] = False\n",
    "    config_encoder['dropout'] = hparams[HP_DROPOUT]\n",
    "    config_encoder['batch_norm'] = hparams[HP_BATCH_NORM]\n",
    "    \n",
    "    \n",
    "    device = torch.device(\"cuda\")\n",
    "    encoder, decoder = Encoder(**config_encoder), Decoder(**config_decoder)\n",
    "    encoder, decoder = encoder.to(device), decoder.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "      list(encoder.parameters()) + list(decoder.parameters()), lr=1e-3)\n",
    "    loss_function = torch.nn.CrossEntropyLoss(ignore_index=wordvoc.word2idx['[PAD]'])\n",
    "\n",
    "    loss = trainer(count_of_epoch = EPOCHS,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        model = (encoder, decoder),\n",
    "        dataset = data.head(n=10*64 + 10)[\"message\"], \n",
    "        tokenizer=tokenizer,\n",
    "        word2idx = wordvoc.word2idx,\n",
    "        loss_function = loss_function,\n",
    "        optimizer = optimizer, callback=callback(writer, batch_generator(data[40*64 + 100: 42*64 + 100][\"message\"].values, wordvoc.word2idx, tokenizer, BATCH_SIZE), prob_accuracy, METRICS_NAME , hparams, DELIMETER))\n",
    "\n",
    "    \n",
    "    print(loss)\n",
    "    return loss\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=NUM_TRIALS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшие значнеия гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_dim': 88,\n",
       " 'dropout': 0.4971203614510987,\n",
       " 'emb_dim': 14,\n",
       " 'hidden_dim': 12,\n",
       " 'batch_norm': True,\n",
       " 'layers_count': 3}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Минимальный loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.271160375539254"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Неожиданным результатом оказалось то, что на обученеи влиет во основном размер словаря, данных не достаточно чтобы сказать, что остальные гиперпараметры влияет на качество восстановления. Возможно это связано с тем, что изначально были подобраны оптимальные параметры модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результат обучения на подобранных параметрах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "wordvoc.rebuild_vocabulary(90000)\n",
    "config_decoder = dict()\n",
    "config_decoder['vocab_dim'] = len(wordvoc.word2idx)\n",
    "config_decoder['output_dim'] = len(wordvoc.word2idx)\n",
    "config_decoder['emb_dim'] = 256\n",
    "config_decoder['hidden_dim'] = 512\n",
    "config_decoder['num_layers'] = 2\n",
    "config_decoder['bidirectional'] = False\n",
    "config_decoder['dropout'] = study.best_params['dropout']\n",
    "config_decoder['batch_norm'] = study.best_params['batch_norm']\n",
    "config_decoder['word2idx'] = wordvoc.word2idx\n",
    "\n",
    "config_encoder = dict()\n",
    "config_encoder['vocab_dim'] = len(wordvoc.word2idx)\n",
    "config_encoder['emb_dim'] = 256\n",
    "config_encoder['hidden_dim'] = 512\n",
    "config_encoder['num_layers'] = 5\n",
    "config_encoder['bidirectional'] = False\n",
    "config_encoder['dropout'] = study.best_params['dropout']\n",
    "config_encoder['batch_norm'] = study.best_params['batch_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder = Encoder(**config_encoder), Decoder(**config_decoder)\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "encoder.apply(init_weights)\n",
    "decoder.apply(init_weights)\n",
    "encoder, decoder = encoder.to(device), decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-3)\n",
    "loss_function = torch.nn.CrossEntropyLoss(ignore_index=wordvoc.word2idx['[PAD]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f646b989cf4ea6b9be08fb0d17f3ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee0b4d9e9ea48a2ba8ccd05cd296d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8638f8103b4bbb9d66ec7379e25ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183f4fa79b74450b993b6751184a811c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95478bc2aeb5419186676ea8b5e21097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7349ef2010024a0e93456ce2e0505ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1d035f50af42f19caf2d8c083e6aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9dd4490c35d47b6b311ff07f4c1a1ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4bb457669d41b197ae980fc5ce8171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "debc04dea4ab4035a0f47f20c0de8aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272916b774f04092b0f33297e4092707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17088292b509403792b24b9234738480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5109a64250ce48079f8be3a8ffe007cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e51ed62d6894627a548d196be84c1a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3709397bd7d14dc0b3bd56425ec7a948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7104b300e564d95b69880bcfad95f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer(count_of_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m      2\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m      3\u001b[0m         model \u001b[38;5;241m=\u001b[39m (encoder, decoder),\n\u001b[1;32m      4\u001b[0m         dataset \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mhead(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m64\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m10\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m      5\u001b[0m         tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m      6\u001b[0m         word2idx \u001b[38;5;241m=\u001b[39m wordvoc\u001b[38;5;241m.\u001b[39mword2idx,\n\u001b[1;32m      7\u001b[0m         loss_function \u001b[38;5;241m=\u001b[39m loss_function,\n\u001b[1;32m      8\u001b[0m         optimizer \u001b[38;5;241m=\u001b[39m optimizer)\n",
      "Cell \u001b[0;32mIn[13], line 18\u001b[0m, in \u001b[0;36mtrainer\u001b[0;34m(count_of_epoch, batch_size, model, dataset, word2idx, loss_function, optimizer, tokenizer, callback)\u001b[0m\n\u001b[1;32m     13\u001b[0m     number_of_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mbatch_size \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mlen\u001b[39m(dataset)\u001b[38;5;241m%\u001b[39mbatch_size\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     14\u001b[0m     generator \u001b[38;5;241m=\u001b[39m tqdm\u001b[38;5;241m.\u001b[39mnotebook\u001b[38;5;241m.\u001b[39mtqdm(\n\u001b[1;32m     15\u001b[0m         batch_generator(dataset, word2idx, tokenizer, batch_size),\n\u001b[1;32m     16\u001b[0m         leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, total\u001b[38;5;241m=\u001b[39mnumber_of_batch)\n\u001b[0;32m---> 18\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m train_epoch(\n\u001b[1;32m     19\u001b[0m         train_generator \u001b[38;5;241m=\u001b[39m generator, model \u001b[38;5;241m=\u001b[39m model, \n\u001b[1;32m     20\u001b[0m         loss_function \u001b[38;5;241m=\u001b[39m loss_function, \n\u001b[1;32m     21\u001b[0m         optimizer \u001b[38;5;241m=\u001b[39m optima, callback\u001b[38;5;241m=\u001b[39mcallback)\n\u001b[1;32m     23\u001b[0m     iterations\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain epoch loss\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch_loss})\n\u001b[1;32m     24\u001b[0m model[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(train_generator, model, loss_function, optimizer, callback)\u001b[0m\n\u001b[1;32m      3\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m it, (batch_of_x, batch_of_y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_generator):\n\u001b[0;32m----> 5\u001b[0m     local_loss \u001b[38;5;241m=\u001b[39m train_on_batch(\n\u001b[1;32m      6\u001b[0m         model, batch_of_x, batch_of_y, optimizer, loss_function)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "Cell \u001b[0;32mIn[64], line 23\u001b[0m, in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, batch_of_x, batch_of_y, optimizer, loss_function)\u001b[0m\n\u001b[1;32m     20\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mparameters(), CLIP)\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep(closure)\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m closure()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem()\n",
      "Cell \u001b[0;32mIn[64], line 9\u001b[0m, in \u001b[0;36mtrain_on_batch.<locals>.closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m():\n\u001b[0;32m----> 9\u001b[0m     d, h, c \u001b[38;5;241m=\u001b[39m encoder(batch_of_x\u001b[38;5;241m.\u001b[39mto(encoder\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[1;32m     10\u001b[0m     output \u001b[38;5;241m=\u001b[39m decoder(\n\u001b[1;32m     11\u001b[0m         batch_of_y\u001b[38;5;241m.\u001b[39mto(decoder\u001b[38;5;241m.\u001b[39mdevice), \n\u001b[1;32m     12\u001b[0m         h\u001b[38;5;241m=\u001b[39mh\u001b[38;5;241m.\u001b[39mto(decoder\u001b[38;5;241m.\u001b[39mdevice)[:, \u001b[38;5;241m-\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mnum_layers:, :], \n\u001b[1;32m     13\u001b[0m         c\u001b[38;5;241m=\u001b[39mc\u001b[38;5;241m.\u001b[39mto(decoder\u001b[38;5;241m.\u001b[39mdevice)[:, \u001b[38;5;241m-\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mnum_layers:, :])\n\u001b[1;32m     15\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_function(output[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m), batch_of_y\u001b[38;5;241m.\u001b[39mto(decoder\u001b[38;5;241m.\u001b[39mdevice)[:, \u001b[38;5;241m1\u001b[39m:])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer(count_of_epoch = 20,\n",
    "        batch_size = 16,\n",
    "        model = (encoder, decoder),\n",
    "        dataset = data.head(n=100*64 + 10)[\"message\"], \n",
    "        tokenizer=tokenizer,\n",
    "        word2idx = wordvoc.word2idx,\n",
    "        loss_function = loss_function,\n",
    "        optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним сеть, чтобы потом можно ее восстановить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), 'encoder_opt.pt')\n",
    "torch.save(decoder.state_dict(), 'decoder_opt.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем сохраненную сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.load_state_dict(torch.load('encoder_opt.pt'))\n",
    "decoder.load_state_dict(torch.load('decoder_opt.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = torch.tensor([[wordvoc.word2idx.get(char, 0) for char in tokenizer.tokenize(data[\"message\"][1200])]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy. spending time with mum'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"message\"][1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itsokayFallagoingtobed.\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "d, h, c = encoder(sent.to(encoder.device))\n",
    "indexes = torch.argmax(\n",
    "    decoder(\n",
    "        max_len=100,\n",
    "        h=h.to(decoder.device)[:, -decoder.num_layers:, :], \n",
    "        c=c.to(decoder.device)[:, -decoder.num_layers:, :]), dim=-1).detach().cpu().numpy()[0]\n",
    "list_of_char = []\n",
    "for idx in indexes:\n",
    "    if idx == wordvoc.word2idx['[SEP]']:\n",
    "        break\n",
    "    list_of_char.append(wordvoc.idx2word[idx])\n",
    "print(''.join(list_of_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inthesametime\n",
      "checkedout\n",
      "I'mstuckin\n",
      "imiforwardto\n",
      "imissher.\n",
      "I'mstuckwith\n",
      ":://tinyurl.com/x##q##q##x##x\n",
      "Poutm##r\n",
      "theco##ochi##k\n",
      "haveagoodday\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    indexes = torch.argmax(\n",
    "        decoder(max_len=100,\n",
    "                h=0.1*torch.randn(\n",
    "                    (1, decoder.num_layers, decoder.num_direction*decoder.hidden_dim)).to(\n",
    "                        decoder.device\n",
    "                ), \n",
    "                c=torch.randn(\n",
    "                    (1, decoder.num_layers, decoder.num_direction*decoder.hidden_dim)).to(\n",
    "                    decoder.device\n",
    "                )), dim=-1).detach().cpu().numpy()[0]\n",
    "    list_of_char = []\n",
    "    for idx in indexes:\n",
    "        if idx == wordvoc.word2idx['[SEP]']:\n",
    "            break\n",
    "        list_of_char.append(wordvoc.idx2word[idx])\n",
    "    print(''.join(list_of_char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ручная подборка параметров помогла достичь более осознаных предложений. Можно сделать вывод, что при подборке гиперпараметров также важна точна с которй мы начинаем. Для слишком маленькой сети модель просто обучается на самый распространенный символ, но начиная с какого-то порогого размера сети она уже обучается дальше."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
